{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Granger Casuality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "# 确保PyTorch可以访问GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载数据\n",
    "data_path = 'Input/processed/dataset_derangement.csv'  # 请替换为正确的路径\n",
    "data = pd.read_csv(data_path)\n",
    "# 假设数据已经按照时间和stay_id排序\n",
    "selected_columns = data.columns.drop(['admission_id', 'hour'])\n",
    "data = data[selected_columns].values\n",
    "\n",
    "# # 数据标准化\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "X = torch.tensor(data, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.Models.cMLP import cMLP\n",
    "# 初始化模型\n",
    "hidden_layers = [64]  # 可以根据需要调整隐藏层的大小和数量\n",
    "activation = 'relu'\n",
    "lag = 5  # 可以根据需要调整\n",
    "model = cMLP(num_series=X.shape[-1], lag=lag, hidden=hidden_layers, activation=activation).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.Models.cMLP import train_model_ista, train_model_adam\n",
    "# 训练模型\n",
    "lr = 1e-3  # 学习率\n",
    "lam = 2e-3  # L1正则化系数\n",
    "lam_ridge = 1e-2  # Ridge正则化系数\n",
    "max_iter = 5000  # 迭代次数\n",
    "log_intervel = 1000  # 每隔多少次迭代记录一次损失\n",
    "train_loss_list = train_model_adam(\n",
    "    model, X, lam=lam, lam_ridge=lam_ridge, lr=lr, penalty='H', max_iter=max_iter,\n",
    "    check_every=log_intervel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "GC = [torch.norm(net.layers[0].weight, dim=(0, 2)) for net in model.networks]\n",
    "GC = torch.stack(GC)\n",
    "GC_adj = (GC > 0.001).int().cpu().numpy() # 0.001为阈值，可自行设定\n",
    "n = len(GC_adj)  # 获取邻接矩阵的大小\n",
    "\n",
    "# 加载数据\n",
    "data_path = 'Input/processed/dataset_derangement.csv'  # 请替换为正确的路径\n",
    "data = pd.read_csv(data_path)\n",
    "labels = data.columns.drop(['admission_id', 'hour']).tolist()\n",
    "# 创建一个标签映射，将节点的索引映射到标签名\n",
    "label_dict = {i: labels[i] for i in range(n)}\n",
    "\n",
    "# 创建图对象\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):  # 只需遍历矩阵上三角来避免重复添加边\n",
    "        if GC_adj[i, j] == 1:  # 如果i和j之间有边\n",
    "            G.add_edge(i, j)\n",
    "            # 为确保节点标签只为实际有边相连的节点设置，可以在此处添加节点，并指定标签\n",
    "            G.nodes[i]['label'] = labels[i]\n",
    "            G.nodes[j]['label'] = labels[j]\n",
    "            \n",
    "nx.write_graphml(G, 'Output/Results/Granger_Causality_Graph_Derangement.graphml')\n",
    "\n",
    "# 使用nx.draw_networkx()来绘制图，因为它允许更多自定义，包括节点的标签\n",
    "pos = nx.spring_layout(G)  # 生成布局\n",
    "nx.draw_networkx_nodes(G, pos, node_color='lightblue')\n",
    "nx.draw_networkx_edges(G, pos, edge_color='gray')\n",
    "nx.draw_networkx_labels(G, pos, labels={i: G.nodes[i]['label'] for i in G.nodes()})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "G = nx.read_graphml('Output/Results/Granger_Causality_Graph_Derangement.graphml')\n",
    "# Calculate GrootRank values for each node\n",
    "dangling_nodes = [node for node, out_degree in G.out_degree() if out_degree == 0]\n",
    "personalization = {}\n",
    "for node in G.nodes():\n",
    "    if node in dangling_nodes:\n",
    "        personalization[node] = 1.0\n",
    "    else:\n",
    "        personalization[node] = 0.5\n",
    "pagerank = nx.pagerank(G, personalization=personalization)\n",
    "pagerank_values = dict(sorted(pagerank.items(), key=lambda x: x[1], reverse=True))\n",
    "# Convert PageRank values to a DataFrame for easier analysis\n",
    "pagerank_df = pd.DataFrame(list(pagerank_values.items()), columns=['Node', 'PageRank'])\n",
    "pagerank_df['Node'] = [item['label'] for item in dict(G.nodes.data()).values()]\n",
    "# Sort the DataFrame by PageRank values in descending order\n",
    "sorted_pagerank_df = pagerank_df.sort_values(by='PageRank', ascending=False)\n",
    "\n",
    "# Take the top 10 nodes by PageRank for visualization\n",
    "top_pagerank_nodes = sorted_pagerank_df.head(10)\n",
    "\n",
    "# Create a bar plot for the top 10 nodes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_pagerank_nodes['Node'], top_pagerank_nodes['PageRank'])\n",
    "plt.xlabel('Node', fontsize=14)\n",
    "plt.ylabel('PageRank Value', fontsize=14)\n",
    "plt.xticks(ticks=top_pagerank_nodes['Node'], labels=top_pagerank_nodes['Node'], rotation=45, fontsize=12)\n",
    "plt.tight_layout()  # Adjust layout to make room for the rotated x-axis labels\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
